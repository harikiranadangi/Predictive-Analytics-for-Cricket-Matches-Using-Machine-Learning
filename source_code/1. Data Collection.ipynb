{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "def process_json_files(folder_path, output_file, start_file=None):\n",
    "    # List all JSON files in the directory\n",
    "    json_files = [f for f in os.listdir(folder_path) if f.endswith('.json')]\n",
    "    \n",
    "    # Sort the list of files\n",
    "    json_files.sort()\n",
    "\n",
    "    # Filter files if a start file is provided\n",
    "    if start_file:\n",
    "        start_index = json_files.index(start_file) + 1\n",
    "        json_files = json_files[start_index:]\n",
    "\n",
    "    # List to hold all processed DataFrames\n",
    "    dfs = []\n",
    "\n",
    "    # Loop through each file\n",
    "    for file in json_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        try:\n",
    "            # Check if the file exists and is not empty\n",
    "            if os.path.exists(file_path) and os.path.getsize(file_path) > 0:\n",
    "                with open(file_path, 'r') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # Normalize JSON data into DataFrame\n",
    "                df = json_normalize(data)\n",
    "                \n",
    "                # Filter columns that start with 'info.' but not 'info.registry'\n",
    "                info_columns = [col for col in df.columns if col.startswith('info.') and not col.startswith('info.registry')\n",
    "                                and not col.startswith('info.players') and not col.startswith('info.supersubs.')]\n",
    "                df = df[info_columns]\n",
    "                \n",
    "                # Remove 'info.' prefix from the column names\n",
    "                df.columns = df.columns.str.replace(\"info.\", \"\", regex=False)\n",
    "                \n",
    "                # Add match_id column with the filename\n",
    "                df['match_id'] = os.path.splitext(file)[0]\n",
    "                \n",
    "                # Append the processed DataFrame to the list\n",
    "                dfs.append(df)\n",
    "            else:\n",
    "                print(f\"File not found or is empty: {file_path}\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from file: {file_path}, Error: {str(e)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred processing file: {file_path}, Error: {str(e)}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    if dfs:\n",
    "        final_df = pd.concat(dfs, ignore_index=True)\n",
    "        # Save the final DataFrame to CSV\n",
    "        final_df.to_csv(output_file, index=False)\n",
    "        print(f\"Processed data saved to: {output_file}\")\n",
    "    else:\n",
    "        print(\"No data processed. Please check the input files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Data\n",
    "old_folder_path = r\"H:\\all matches\\all_json\"\n",
    "old_output_file = r\"D:\\GITHUB\\Cricket_Predictions\\all_matches\\source_data\\Summary\\match_summary\\old_match_summary.csv\"\n",
    "process_json_files(old_folder_path, old_output_file)\n",
    "\n",
    "# New Data\n",
    "new_folder_path = r\"H:\\all matches\\all_json\"\n",
    "new_output_file = r\"D:\\GITHUB\\Cricket_Predictions\\all_matches\\source_data\\Summary\\match_summary\\new_match_summary.csv\"\n",
    "start_file = \"1436482.json\"\n",
    "process_json_files(new_folder_path, new_output_file, start_file=start_file)\n",
    "\n",
    "# Concatenate old and new DataFrames\n",
    "old_final_df = pd.read_csv(old_output_file, low_memory=False)\n",
    "new_final_df = pd.read_csv(new_output_file, low_memory=False)\n",
    "output_file = r\"D:\\GITHUB\\Cricket_Predictions\\all_matches\\source_data\\Summary\\match_summary\\match_summary.csv\"\n",
    "final_df = pd.concat([new_final_df, old_final_df], ignore_index=True)\n",
    "final_df.to_csv(output_file, index=False)\n",
    "print(f\"Concatenated data saved to: {output_file}\")\n",
    "\n",
    "# Display the head of the final DataFrame\n",
    "print(final_df.head())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
