{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and clean data\n",
    "match_df = pd.read_csv(r\"D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\summary_cleaned.csv\")\n",
    "match_df.drop(columns=[\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['match_id', 'season', 'match_date', 'event_name', 'gender',\n",
       "       'match_type', 'team1', 'team2', 'toss_winner', 'toss_decision',\n",
       "       'winner', 'ground'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "match_id         0\n",
       "season           0\n",
       "match_date       0\n",
       "event_name       0\n",
       "gender           0\n",
       "match_type       0\n",
       "team1            0\n",
       "team2            0\n",
       "toss_winner      0\n",
       "toss_decision    0\n",
       "winner           0\n",
       "ground           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df[\"event_name\"] = match_df[\"event_name\"].fillna(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure match_date is a datetime object\n",
    "match_df['match_date'] = pd.to_datetime(match_df['match_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate match_id\n",
    "assert match_df['match_id'].is_unique, \"match_id has duplicates!\"\n",
    "assert not match_df['match_id'].isnull().any(), \"match_id has nulls!\"\n",
    "match_df['match_id'] = match_df['match_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "\n",
    "POSTGRES_CREDENTIALS = {\n",
    "    \"username\": \"postgres\",\n",
    "    \"password\": \"Hari@123\",\n",
    "    \"host\": \"localhost\",\n",
    "    \"port\": \"5432\",\n",
    "    \"database\": \"cricket_data\",\n",
    "}\n",
    "\n",
    "# Optional: Encode the password in case it contains special characters\n",
    "password = urllib.parse.quote(POSTGRES_CREDENTIALS[\"password\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new matches to insert.\n"
     ]
    }
   ],
   "source": [
    "# Create SQLAlchemy engine for PostgreSQL\n",
    "engine = create_engine(\n",
    "    f\"postgresql+psycopg2://{POSTGRES_CREDENTIALS['username']}:{password}@{POSTGRES_CREDENTIALS['host']}:{POSTGRES_CREDENTIALS['port']}/{POSTGRES_CREDENTIALS['database']}\"\n",
    ")\n",
    "\n",
    "# Table name\n",
    "table_name = 'matches'\n",
    "\n",
    "# SQL to create table if it does not exist\n",
    "create_table_query = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "    match_id      INTEGER PRIMARY KEY,\n",
    "    season        VARCHAR(10),\n",
    "    match_date    DATE,\n",
    "    event_name    VARCHAR(100),\n",
    "    gender        VARCHAR(10),\n",
    "    match_type    VARCHAR(20),\n",
    "    team1         VARCHAR(50),\n",
    "    team2         VARCHAR(50),\n",
    "    toss_winner   VARCHAR(50),\n",
    "    toss_decision VARCHAR(10),\n",
    "    winner        VARCHAR(50),\n",
    "    ground        VARCHAR(100)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "# Run everything\n",
    "try:\n",
    "    with engine.connect() as conn:\n",
    "        # Get existing match_ids\n",
    "        existing_ids = pd.read_sql(f\"SELECT match_id FROM {table_name}\", conn)\n",
    "        existing_ids_set = set(existing_ids['match_id'])\n",
    "\n",
    "    # Filter new matches only\n",
    "    new_matches_df = match_df[~match_df['match_id'].isin(existing_ids_set)]\n",
    "\n",
    "    if not new_matches_df.empty:\n",
    "        new_matches_df.to_sql(name=table_name, con=engine, if_exists='append', index=False)\n",
    "        print(f\"{len(new_matches_df)} new match(es) inserted.\")\n",
    "    else:\n",
    "        print(\"No new matches to insert.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\female\\it20_female_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\female\\odi_female_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\female\\odm_female_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\female\\t20_female_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\female\\test_female_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\male\\it20_male_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\male\\mdm_male_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\male\\odi_male_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\male\\odm_male_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\male\\t20_male_match_summary_cleaned.csv\n",
      "Saved: D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\male\\test_male_match_summary_cleaned.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to the full match summary CSV\n",
    "input_file = r\"D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\\summary_cleaned.csv\"\n",
    "\n",
    "# Load the data\n",
    "match_df = pd.read_csv(input_file)\n",
    "\n",
    "# Fill missing gender/match_type just in case\n",
    "match_df['gender'] = match_df['gender'].fillna('unknown')\n",
    "match_df['match_type'] = match_df['match_type'].fillna('unknown')\n",
    "\n",
    "# Base output directory\n",
    "base_output_dir = r\"D:\\GITHUB\\Predictive-Analytics-for-Cricket-Matches-Using-Machine-Learning\\source_data\\Summary\\match_summary\"\n",
    "\n",
    "# Group by gender and match_type\n",
    "for (gender, match_type), group_df in match_df.groupby(['gender', 'match_type']):\n",
    "    gender_dir = os.path.join(base_output_dir, gender.lower())\n",
    "    os.makedirs(gender_dir, exist_ok=True)  # Create the folder if it doesn't exist\n",
    "    \n",
    "    filename = f\"{match_type.lower()}_{gender.lower()}_match_summary_cleaned.csv\"\n",
    "    output_path = os.path.join(gender_dir, filename)\n",
    "\n",
    "    group_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
